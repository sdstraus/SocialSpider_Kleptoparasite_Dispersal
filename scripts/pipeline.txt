

## 11 January 2021
### install some essential packages
# install homebrew
ruby -e "$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/master/install)"

# install pkg-config
brew install pkg-config

# instal xcode
# xcode-select --install

#download wget
# cd ~/Downloads
# curl -O https://ftp.gnu.org/gnu/wget/wget-1.19.5.tar.gz

#extract and configure
# tar -zxvf wget-1.19.5.tar.gz
# cd wget-1.19.5/
# ./configure

#make and test wget
# make
# make install
# wget http://ftp.gnu.org/gnu/wget/wget-1.19.5.tar.gz


brew install wget


### get data from nanuq

bash

# get this command from clicking the Download Read Files button in the NovaSeq Read Sets tab

read -p "Login: " login && read -p "Password: " -s password && echo -n "j_username=$login&j_password=$password" > .auth.txt && chmod 600 .auth.txt && wget -O - "https://ces.genomequebec.com/nanuqMPS/readsetList?projectId=19729&tech=NovaSeq" --no-cookies --no-check-certificate --post-file .auth.txt | wget --no-cookies --no-check-certificate --post-file .auth.txt -ci -; rm -f .auth.txt

*login sstraus
*password 80dh3ceq

## this step took 7 hours

### 16 January 2021
## these files are far too large to handle on my computer, so using zoology server

# in server GSBS folder
### make directories:
mkdir tools
mkdir extras
mkdir clean_data
mkdir raw_data
mkdir clean_data_trim

## copy data to scratch
scp NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1.fastq.gz straus@zoology.ubc.ca:/Shared/homes/s/straus/GBS/raw_reads


scp NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R2.fastq.gz straus@zoology.ubc.ca:/Shared/homes/s/straus/GBS/raw_reads

# create job to extract

nano

#!/bin/bash
#
#SBATCH --account=def-germainr   # replace this with your own account
#SBATCH --job-name=extracted   		# Job name
#
#SBATCH --ntasks=4               # number of processes
#SBATCH --mem-per-cpu=7000M      # memory; default unit is megabytes
#SBATCH --time=7-00:00           # time (DD-HH:MM)
#SBATCH --mail-user=straus@zoology.ubc.ca # Send email updates to you or someone else
#SBATCH --mail-type=ALL          # send an email in all cases (job started, job ended, job aborted)

echo "Running on hostname `hostname`"

cd $SLURM_SUBMIT_DIR
echo "Working directory is `pwd`"

gunzip NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1.fastq.gz

echo "Finished R at `date`."



## start setting up stacks demultiplexing

### make directories
mkdir stacks_demultiplex
mkdir stacks_demultiplex/samples
mkdir stacks_demultiplex/barcodes
mkdir stacks_demulitplex/raw

### put fastq files in raw folder
cp raw_data/*fastq stacks_demulitplex/raw



#rename them to have stacks suffixes
mv stacks_demulitplex/raw/HI.5215.003.LN_PG_Saps_R1.fastq.gz stacks_demulitplex/raw/PG_2019_R1_001.fastq.gz
mv stacks_demulitplex/raw/HI.5215.003.LN_PG_Saps_R2.fastq.gz stacks_demulitplex/raw/PG_2019_R2_001.fastq.gz




########### 27 January 2021 ##############
#created barcodes.txt file in R, that hold barcodes


#in server folder:
### make directories
mkdir stacks_demultiplex
mkdir stacks_demultiplex/samples
mkdir stacks_demultiplex/barcodes
mkdir stacks_demultiplex/raw


### put fastq files in raw folder
cp raw_data/*fastq stacks_demulitplex/raw

# move barcodes.txt into stacks_demultiplex/barcodes
# from folder that holds barcodes.txt
scp barcodes.txt straus@zoology.ubc.ca:/Shared/homes/s/straus/GBS/stacks_demultiplex/barcodes


# installing stacks
wget http://catchenlab.life.illinois.edu/stacks/source/stacks-2.55.tar.gz

# followed these steps: # https://genomicislands.wordpress.com/2013/11/11/installing-stacks-locally-on-a-cluster/


## Libby's
## process_radtags -T 16 -p stacks_demultiplex/raw -o stacks_demultiplex/samples -b stacks_demultiplex/barcodes/PG_2019_bar.txt -e pstI -r -c -q -P


## my 2 file names
NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1.fastq.gz
NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R2.fastq.gz

process_radtags -1 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1.fastq.gz -2 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R2.fastq.gz -b stacks_demultiplex/barcodes/barcodes.txt -o stacks_demultiplex/samples -c -q -r --inline_inline --renz_1 pstI --renz_2 mspI 

# process_radtags -P -p raw -b barcodes/barcodes.txt -o samples -c -q -r --inline_inline --renz_1 pstI --renz_2 mspI 


nano demulti_script.txt
process_radtags -1 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1.fastq.gz -2 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R2.fastq.gz -b stacks_demultiplex/barcodes/barcodes.txt -o stacks_demultiplex/samples -c -q -r --inline_inline --renz_1 pstI --renz_2 mspI 



############ February 10, 2021 ##############
# stacks script.txt &

# need to copy demultiplex folder into cluster
# scp myfile zcumember@zoology.ubc.ca:cluster 

# want the whole folder
scp -r * stacks_demultiplex/ straus@zoology.ubc.ca:cluster
# lol somehow this command copied my whole damn server... ok sure

# from inside folder i want to use...
ssh cluster
ssh crunch03
# logout to move out of crunch/cluster

/Linux/bin/stacks demulti_script.txt &

## ran on cluster, got error message : Found 1 paired input file(s).
## google search, jcatchen says reads need "_R1_" and "_R2_", and i have "_R1" and "_R2"

mv NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1.fastq.gz NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1_001.fastq.gz

mv NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R2.fastq.gz NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R2_001.fastq.gz


nano demulti_script.txt
process_radtags -1 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1_001.fastq.gz -2 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R2_001.fastq.gz -b barcodes/barcodes.txt -o samples -c -q -r --inline_inline --renz_1 pstI --renz_2 mspI 
# gave error that output file didn't exist

# created test barcode of just one individual that was causing problem (test_barcodes.txt)
process_radtags -1 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1_001.fastq.gz -2 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R2_001.fastq.gz -b barcodes/barcodes_set1.txt -o samples -c -q -r --inline_inline --renz_1 pstI --renz_2 mspI 


sh file.txt # to execute text file

# used a test of just one individual -- run took several hours
# Ele_VL_43.6.1.03.1.fq.gz 
# Ele_VL_43.6.1.03.2.fq.gz 


########## 12 February 2021 ###########
# copy folder back into main server folder to take a look at the output

cp cluster/stacks_demultiplex/samples/Ele_VL_43.6.1.03.1.fq.gz GBS/stacks_demultiplex/samples/Ele_VL_43.6.1.03.1.fq.gz

cp cluster/stacks_demultiplex/samples/Ele_VL_43.6.1.03.2.fq.gz GBS/stacks_demultiplex/samples/Ele_VL_43.6.1.03.2.fq.gz

# check file size of directory
du -sh samples
# 57 M
# check size of files within directory
du -bsh *
# 28M	Ele_VL_43.6.1.03.1.fq.gz
# 29M	Ele_VL_43.6.1.03.2.fq.gz


Ele_VL_43.6.1.03.1.fq.gz 
# copied files from test run, some quick diagnostics
wc -l Ele_VL_43.6.1.03.1.fq # 1766196
wc -l Ele_VL_43.6.1.03.2.fq # 1766196

head Ele_VL_43.6.1.03.1.fq # 1766196
head Ele_VL_43.6.1.03.2.fq # 1766196


## split barcode file into 2 sets, copy into server folder
scp barcodes_set1.txt straus@zoology.ubc.ca:/Shared/homes/s/straus/GBS/stacks_demultiplex/barcodes

scp barcodes_set2.txt straus@zoology.ubc.ca:/Shared/homes/s/straus/GBS/stacks_demultiplex/barcodes

# within barcodes file
scp -r * straus@zoology.ubc.ca:cluster
## idk why i was surprised, but again this copied the whole damn thing when i want just one file. 


# run set 1
nano demuli_set1.txt
process_radtags -1 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1_001.fastq.gz -2 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R2_001.fastq.gz -b barcodes/barcodes_set1.txt -o samples -c -q -r --inline_inline --renz_1 pstI --renz_2 mspI 



# run started at 11:26
# ended ~10pm
# 826M lines
# Outputing details to log: 'samples/process_radtags.raw.log'

#1652322694 total sequences
# 781023256 barcode not found drops (47.3%)
#    435475 low quality read drops (0.0%)
# 277079792 RAD cutsite not found drops (16.8%)
# 593784171 retained reads (35.9%)



# run set 2
nano demuli_set2.txt
process_radtags -1 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R1_001.fastq.gz -2 raw/NS.1465.002.NoSequence_i5---phiX_index.Straus_1_R2_001.fastq.gz -b barcodes/barcodes_set2.txt -o samples -c -q -r --inline_inline --renz_1 pstI --renz_2 mspI 

scp demulti_set2.txt straus@zoology.ubc.ca:cluster

sh demulti_set2.txt &
# start: 8:03am
# expected end: ~7pm
# actual end: ~10
# 826M lines

#1652322694 total sequences
# 811078100 barcode not found drops (49.1%)
#    506520 low quality read drops (0.0%)
#  55308651 RAD cutsite not found drops (3.3%)
# 785429423 retained reads (47.5%)

# total retained: 83.4%, yikes

# mv process_radtags.raw.log process_radtags_set2.raw.log

# are all the samples here?
# first i'm going to move all the .rem files into a new dir

mv *rem.1.fq.gz removed
mv *rem.2.fq.gz removed

# inside removed folder, #924 files, 924/2 = 462
ls | wc -l

# i need to know if re-running process_radtags on the same set messed up anything
# test individual:
Ex02.8.1.fq.gz #232M
Ex02.8.2.fq.gz #245M

mkdir test_set2
cp -t test_set2 Ex02.8.1.fq.gz Ex02.8.2.fq.gz 
cp {Ex02.8.1.fq.gz,Ex02.8.2.fq.gz} test_set2

wc -l Ex02.8.2.fq # 15049420
wc -l Ex02.8.1.fq #15049420
# look at some random point in the middle
tail -n +1000 Ex02.8.1.fq | head -n 15


#### many samples have really small file sizes:
53M	Guac_VB_8.5.6.01.1.fq.gz
53M	Guac_VB_8.5.6.01.2.fq.gz
49M	Guac_VB_8.5.6.02.1.fq.gz
50M	Guac_VB_8.5.6.02.2.fq.gz
46M	Guac_VB_8.5.6.03.1.fq.gz
46M	Guac_VB_8.5.6.03.2.fq.gz
46M	Guac_VB_8.5.6.04.1.fq.gz
47M	Guac_VB_8.5.6.04.2.fq.gz
48M	Guac_VB_8.5.6.05.1.fq.gz
49M	Guac_VB_8.5.6.05.2.fq.gz
55M	Guac_VB_8.5.6.06.1.fq.gz
56M	Guac_VB_8.5.6.06.2.fq.gz

# move NS.1465.002.Index_19.Straus_5* to server
scp NS.1465.002.Index_19.Straus_5* straus@zoology.ubc.ca:/Shared/homes/s/straus/GBS/stacks_demultiplex/raw


# rename for stacks
mv NS.1465.002.Index_19.Straus_5_R1.fastq.gz NS.1465.002.Index_19.Straus_5_R1_001.fastq.gz
mv NS.1465.002.Index_19.Straus_5_R2.fastq.gz NS.1465.002.Index_19.Straus_5_R2_001.fastq.gz

scp NS.1465.002.Index_19.Straus_5* straus@zoology.ubc.ca:crunch

nano dem_straus5_set1.txt
process_radtags -1 raw/NS.1465.002.Index_19.Straus_5_R1_001.fastq.gz -2 raw/NS.1465.002.Index_19.Straus_5_R2_001.fastq.gz -b barcodes/barcodes_set1.txt -o samples -c -q -r --inline_inline --renz_1 pstI --renz_2 mspI 

cp barcodes_set1.txt ../stacks_demultiplex/barcodes
cp barcodes_set2.txt ../stacks_demultiplex/barcodes

#Start dem_straus5_set1.txt at 6:15pm
270866 total sequences
253948 barcode not found drops (93.8%)
     1 low quality read drops (0.0%)
 15858 RAD cutsite not found drops (5.9%)
  1059 retained reads (0.4%)
  
  
  nano dem_straus5_set2.txt
process_radtags -1 raw/NS.1465.002.Index_19.Straus_5_R1_001.fastq.gz -2 raw/NS.1465.002.Index_19.Straus_5_R2_001.fastq.gz -b barcodes/barcodes_set2.txt -o samples -c -q -r --inline_inline --renz_1 pstI --renz_2 mspI 

270866 total sequences
264554 barcode not found drops (97.7%)
     0 low quality read drops (0.0%)
  5753 RAD cutsite not found drops (2.1%)
   559 retained reads (0.2%)


### 15 June 2021 ###

# download reference genome from: https://www.ncbi.nlm.nih.gov/genome/83943
# Anelosimus studiosus

# move ref genome into server
scp Anelosimus_ref_genome.fna.gz straus@zoology.ubc.ca:/Shared/homes/s/straus/GBS/

scp Anelosimus_ref_genome.fna.gz straus@zoology.ubc.ca:cluster/alignment/ref


## we're starting the analyses with just Anelosimus eximius and their kleptos
# move these into their own folder

mkdir eximius
mv Ex* eximius

# repeat for each bc i think this will be helpful to have folder for each spp later on
mkdir domingo
mv Dom* domingo

mkdir elegans
mv Ele* elegans

mkdir guac
mv Guac* guac
# bc i can't spell...
mv Gauc* guac

### need to unzip and index reference genome
gunzip Anelosimus_ref_genome.fna.gz


# index
bwa index ref/Anelosimus_ref_genome.fna


## output

#[bwt_gen] Finished constructing BWT in 475 iterations.
#[bwa_index] 3077.04 seconds elapse.
#[bwa_index] Update BWT... 20.79 sec
#[bwa_index] Pack forward-only FASTA... 24.81 sec
#[bwa_index] Construct SA from BWT and Occ... client_loop: send disconnect: Broken pipe

# it was disconnected bc I went idle... trying again using nohup command

cat > index_ref.sh   #then paste text  (ctrl-d to finish)

-------
#!/bin/bash
#script to index reference genome
bwa index ref/Anelosimus_ref_genome.fna

------
chmod 755 index_ref.sh

nohup bash ./index_ref.sh &



## stuff from Libby's that seems like it will soon be helpful
# tell it where the executables are
bwa="/Linux/bin/bwa-0.7.10"
picard="/Linux/picard"
samtools="/Linux/bin/samtools"


## 16 June 2021

# in R, I separated out prefixes for each individual belonging to either:
# eximius, N1, or F2.


### alignment

cat > extras/prefix.list_stacks.bwa
-----------
Ex11.3
Ex11.4
Ex11.5
Ex12.1
Ex12.7
Ex14.2
Ex14.4
Ex01.3
Ex02.3
Ex05.5
Ex06A.5
Ex06B.1
Ex06B.6
Ex02.6
Ex02.8
Ex05.3
Ex05.6
Ex06A.6
Ex06B.3
Ex06B.5
Ex06B.8
Ex12.5
Ex05.1
Ex06A.3
Ex07.1
Ex07.3
Ex08.1
Ex08.3
Ex06A.1
Ex06A.2
Ex06B.4
Ex06B.7
Ex07.5
Ex08.7
Ex08.8
Ex12.3
Ex12.6
Ex17.3
Ex06B.2
Ex07.2
Ex08.6
Ex02.2
Ex02.4
Ex07.4
Ex07.6
Ex07.8
Ex08.2
Ex10.2
Ex10.5
Ex11.1
Ex14.5
Ex01.1
Ex02.11
Ex05.13
Ex02.14
Ex02.1
Ex19.4
Ex19.7
Ex12.14
Ex19.11
Exi_VL_29.0.1.02
Exi_VL_29.0.1.03
Exi_VL_29.0.1.05
Exi_VL_29.0.1.06
Exi_VL_29.0.2.01
Exi_VL_29.0.2.02
Exi_VL_47.3.1.04
Exi_VL_47.3.1.05
Exi_VL_9.5.2.01
Exi_VL_9.5.2.02
Exi_VL_43.6.2.03
Exi_VL_24.0.01
Exi_VL_24.0.03
Exi_VL_24.0.04
Exi_VL_24.0.05
Exi_VL_10.5.01
Exi_VL_10.5.02
Exi_VL_41.2.01
Exi_VL_41.2.02
Exi_VL_41.2.03
Exi_VL_41.2.04
Exi_VL_41.2.05
Exi_VL_17.5.01
Exi_VL_17.5.03
Exi_VL_17.5.05
Exi_VL_17.5.06
Exi_VL_Bridge.1.01
Exi_VL_Bridge.1.03
Exi_VL_Bridge.1.04
Exi_VL_24.1.01
Exi_VL_24.1.02
Exi_VL_24.1.03
Exi_VL_24.1.04
Exi_VL_24.1.05
Exi_VL_24.1.06
Exi_VL_9.5.1.01
Exi_VL_9.5.1.02
Exi_VL_9.5.1.03
Exi_VL_Bridge.1.06
Exi_VL_Bridge.1.07
Exi_VL_10.5.08
Exi_VL_9.5.1.05
Exi_VL_29.0.1.07
Exi_VL_29.0.1.08
Exi_VL_29.0.1.09
Exi_VL_29.0.2.06
Exi_VL_29.0.2.07
Exi_VL_29.0.2.08
Exi_VL_Bridge.1.05
Exi_VL_10.5.04
Exi_VL_10.5.05
Exi_VL_10.5.06
Exi_VL_10.5.07
Exi_VL_9.5.01
Exi_Archi_11.8.1.01
Exi_Archi_11.8.1.02
Exi_Archi_11.8.1.03
Exi_Archi_11.8.1.04
Exi_Archi_11.8.1.05
Exi_Archi_11.8.3.01
Exi_Archi_11.8.3.02
Exi_Archi_11.8.3.04
Exi_Archi_11.8.3.05
Exi_Archi_11.8.3.06
Exi_Archi_11.8.5.01
Exi_Archi_11.8.5.02
Exi_Archi_11.8.5.03
Exi_Archi_11.8.5.04
Exi_Archi_11.8.1.06
Exi_Archi_11.8.1.07
Exi_Archi_11.8.1.08
Exi_Archi_11.8.1.09
Exi_Archi_11.8.1.10
Exi_Archi_11.8.2.01
Exi_Archi_11.8.2.02
Exi_Archi_11.8.2.03
Exi_Archi_11.8.4.05
Exi_Archi_11.8.5.05
-----------


cat > align_stacks.sh   #then paste text  (ctrl-d to finish)
-------------
#!/bin/bash
   
# set up variable names
clean_data=~/alignment/clean_data
bam=~/alignment/bam
sam=~/alignment/bam
ref_file=~/alignment/ref/Anelosimus_ref_genome.fna
 
#Then loop through the samples
while read name
  do
    $bwa mem \
    -R "@RG\tID:$name\tSM:$name\tPL:ILLUMINA" \
    $ref_file \
    $clean_data/$name.R1.fq \
    $clean_data/$name.R2.fq \
    -t 1 > $bam/$name.sam;

    samtools view -bh $bam/$name.sam |\
    samtools sort > $bam/$name.sort.bam;
    samtools index $bam/$name.sort.bam
  done < bam/samplelist.txt

---------------


chmod 755 align_stacks.sh

nohup bash ./align_stacks.sh &


## not working, try with just single individual to get it running
Ex11.3

bwa mem -M ref/Anelosimus_ref_genome.fna clean_data/Ex11.3.1.fq clean_data/Ex11.3.2.fq > sam/Ex11.3.sam

samtools view -bh sam/Ex11.3.sam | samtools sort > bam/Ex11.3.sort.bam 


####### zero reads were mapped...
#going to try again with P. tep genome
# https://www.ncbi.nlm.nih.gov/genome/13270?genome_assembly_id=317962


scp Ptep_ref.fna.gz straus@zoology.ubc.ca:cluster/alignment/ref

# use screen to run program in background:
# https://linuxize.com/post/how-to-use-linux-screen/
screen -S index_align
bash align_index.sh

# detach with ctrl+a d; resume with screen -r, check which screens open with screen -ls
# start sesh with screen


#### had to re-do demultiplexing
# set 2
1652322694 total sequences
 811078100 barcode not found drops (49.1%)
    506520 low quality read drops (0.0%)
  55308651 RAD cutsite not found drops (3.3%)
 785429423 retained reads (47.5%)
 
 # set 1
 1652322694 total sequences
 811078100 barcode not found drops (49.1%)
    506520 low quality read drops (0.0%)
  55308651 RAD cutsite not found drops (3.3%)
 785429423 retained reads (47.5%)
 
 scp eximius_prefix.txt straus@zoology.ubc.ca:cluster/alignment/bam
 # deleted all sam/bam files before rerun, check progress witih:
 ls -lR *.sam | wc -l
 
 
## ok, the Anelosimus studiosus genome has more mapped reads for a small subset, so i am going to realign now that i know it works to A studiosus


 
 scp samplelist.txt straus@zoology.ubc.ca:cluster/alignment/bam
 
 # count number of reads
 samtools view -c SAMPLE.bam

# count number of aligned reads
samtools view -c -F 260 SAMPLE.bam

 # count unumber of reads with MAPQ over 30
 samtools view -c -q 30 SAMPLE.bam 
  
  
# copy population map (made in R) to cluster

scp eximius_popmap* straus@zoology.ubc.ca:GBS/ref_map
 
 
 nano ref_map.sh
----------
ref_map.pl -T 8 --popmap ~/ref_map/pop_maps/archi_colony_popmap.txt \ 
        -o ~/ref_map/stacks/ 
        -s ~/ref_map/samples_archi/Exi_Archi_11.8.1.01.sam \ 
        -s ~/ref_map/samples_archi/Exi_Archi_11.8.1.02.sam \
        -s ~/ref_map/samples_archi/Exi_Archi_11.8.1.03.sam \
        -s ~/ref_map/samples_archi/Exi_Archi_11.8.1.04.sam \
        -s ~/ref_map/samples_archi/Exi_Archi_11.8.1.05.sam \
        -s ~/ref_map/samples_archi/Exi_Archi_11.8.1.06.sam \
        -s ~/ref_map/samples_archi/Exi_Archi_11.8.1.07.sam \ 
        -X "populations:--fstats"

----------------
#!/bin/bash
ref_map=~/ref_map
pop_maps=~/ref_map/pop_maps

ref_map.pl -T 8 --popmap ~/ref_map/pop_maps/archi_colony_popmap.txt \ 
        -o ~/ref_map/stacks/ \
        --samples ~/ref_map/samples_archi/ \ 
        -X "populations:--fstats" 
        
------------------        
        
    #!/bin/bash
ref_map=~/ref_map
pop_maps=~/ref_map/pop_maps

ref_map.pl -T 8 --popmap $pop_maps/archi_colony_popmap.txt -o $ref_map/stacks/ --samples $ref_map/samples_archi/


        ----------------
        
# getting same error that it can't read my bam files... i have sam files only, but it should be able to take those? convert to bam

cat > bamsort.sh   #then paste text  (ctrl-d to finish)
-------------
#!/bin/bash

while read name
  do
  	samtools view -S -b $name.sam > $name.bam;
  	samtools sort $name.bam > $name.sort.bam
  done < samplelist.txt

---------------

# now getting error:
#Error: BAM file is not properly sorted; 3th record '203_2_1101_13847_1047' at #VSFD01010390.1:9539 should come before previously seen position VSFD01372265.1:875.
#Error: (At the 3th record in file #'/home/straus/ref_map/samples_archi/Exi_Archi_11.8.1.01.bam'.)
#Aborted.

# doesn't like my ".sort.bam" bc looking for ".bam"
# rename to bam, moved unsorted bams into new folder

cat > rename.sh   #then paste text  (ctrl-d to finish)
-------------
#!/bin/bash

while read name
  do
	mv $name.sort.bam $name.bam
  done < samplelist.txt

---------------

## 01 July 2021
## running ref_map.sh on whole set of A. eximius

---

#!/bin/bash
ref_map=~/ref_map
pop_maps=~/ref_map/pop_maps
samples=~/ref_map/samples/sorted_bam

ref_map.pl -T 8 --popmap $pop_maps/eximius_popmap_colony.txt -o $ref_map/stacks/ --samples $samples

---
# default run repots Fis, but not any other Fstat, re-running populations and including output to vcf so i can use with R

populations -P ./stacks/ --popmap ./pop_maps/eximius_popmap_colony.txt --vcf -t 8 --fstats


## 03 July 2021
# 
# gstacks log:
#
#Read 345067536 BAM records:
#kept 30798348 primary alignments (9.4%), of which 18148559 reverse reads
#skipped 83597381 primary alignments with insufficient mapping qualities (25.6%)
#skipped 59799228 excessively soft-clipped primary alignments (18.3%)
#skipped 152474769 unmapped reads (46.7%)
#skipped some suboptimal (secondary/supplementary) alignment records

#Per-sample stats (details in 'gstacks.log.distribs'):
#read 2500489.4 records/sample (68-27884133)
#kept 0.8%-16.2% of these

#Built 21345 loci comprising 12649789 forward reads and 5123271 matching paired-end reads; #mean insert length was 310.0 (sd: 111.2).

#Genotyped 21345 loci:
#effective per-sample coverage: mean=-nanx, stdev=-nanx, min=1.0x, max=421.3x
#mean number of sites per locus: 191.1
#a consistent phasing was found for 27849 of out 41689 (66.8%) diploid loci needing phasing


# soo, alignment sucked, and very few reads were kept. going to try de novo 
# dry run first (-d command)


cat > denovo_eximius.sh  
----------------

#!/bin/bash
denovo_map=~/denovo_map
pop_maps=~/pop_maps
samples=~/stacks_demultiplex/samples/eximius/exi

denovo_map.pl -T 8 -d --popmap $pop_maps/eximius_popmap_colony.txt -o ~/denovo_map/stacks/ --samples $samples --paired -X "populations:--fstats" 
        

----------------

# seems to have worked, now running for real (deleting -d)

cat > denovo_eximius.sh  
----------------

#!/bin/bash
denovo_map=~/denovo_map
pop_maps=~/pop_maps
samples=~/stacks_demultiplex/samples/eximius/exi

denovo_map.pl -T 14 --popmap $pop_maps/eximius_popmap_colony.txt -o ~/denovo_map/stacks/ --samples $samples --paired -X "populations:--fstats" 
        

----------------
# started at 11:45am on 03 July, finished by 8:00am 04 July


# some meaningful outputs:
Final coverage: mean=17.58; stdev=17.92; max=559; n_reads=677983(65.8%)



Attempted to assemble and align paired-end reads for 259063 loci:
  0 loci had no or almost no paired-end reads (0.0%);
  1207 loci had paired-end reads that couldn't be assembled into a contig (0.5%);
  For the remaining 257856 loci (99.5%), a paired-end contig was assembled;
    Average contig size was 268.7 bp;
  103793 paired-end contigs overlapped the forward region (40.3%)
    Mean overlap: 28.2bp; mean size of overlapped loci after merging: 227.1;
  Out of 193712102 paired-end reads in these loci (mean 745.9 reads per locus),
    192342958 were successfuly aligned (99.3%);
  Mean insert length was 231.1, stdev: 50.8 (based on aligned reads in overlapped loci).

Genotyped 257854 loci:
  effective per-sample coverage: mean=25.6x, stdev=23.0x, min=3.6x, max=175.0x
  mean number of sites per locus: 262.5
  a consistent phasing was found for 168168 of out 275746 (61.0%) diploid loci needing phasing

Removed 0 loci that did not pass sample/population constraints from 257854 loci.
Kept 257854 loci, composed of 69296043 sites; 394 of those sites were filtered, 142570 variant sites remained.
Number of loci with PE contig: 257642.00 (99.9%);
  Mean length of loci: 258.84bp (stderr 0.11);
Number of loci with SE/PE overlap: 103793.00 (40.3%);
  Mean length of overlapping loci: 221.42bp (stderr 0.11); mean overlap: 28.25bp (stderr 0.02);
Mean genotyped sites per locus: 262.49bp (stderr 0.10).


# filtering using populations

populations -P ./denovo_map/stacks/ --popmap ./pop_maps/eximius_popmap_colony.txt -t 14 --min-maf 0.05 --max-obs-het 0.7 --fstats --vcf


# want output in structure format so i can use with other packages...
populations -P ./denovo_map/stacks/ --popmap ./pop_maps/eximius_popmap_colony.txt -t 14 --min-maf 0.05 --max-obs-het 0.7 --fstats --vcf --structure



### okie dokie, I ultimately want to split between colonies AND sites, so i'm going to do that

cat > denovo_eximius.sh  
----------------

#!/bin/bash
denovo_map=~/denovo_map
pop_maps=~/pop_maps
samples=~/stacks_demultiplex/samples/eximius/exi

denovo_map.pl -T 14 --popmap $pop_maps/eximius_popmap_colony_site.txt -o ~/denovo_map/stacks/ --samples $samples -M 2 -n 3 --paired
        
----------------
# started run at 9:58am, ended at ~4:45pm

# rerunning filtering step with new popmap

populations -P ./denovo_map/stacks/ --popmap ./pop_maps/eximius_popmap_colony_site.txt -t 14 --min-maf 0.05 --max-obs-het 0.7 --fstats --vcf
------------

# following the biol 525b instructions 
# use plink to convert vcf file to bed files (to use later with admixture)

gzip populations.snps.vcf

plink --make-bed --vcf populations.snps.c_chroms.vcf.gz --out populations.snps.c_chroms --set-missing-var-ids @:# --double-id --allow-extra-chr --noweb

## ok this is isn't working, trying a different route of filting

vcftools --gzvcf populations.snps.vcf.gz --missing-indv --out populations.snps

# doesn't like the numbers in the chromosome column
# found some code online to help with my problem
gzip -cd populations.snps.vcf.gz | sed -E '/^#/! s/^/c/' | gzip > populations.snps.c_chroms.vcf.gz

bgzip -c populations.snps.vcf > populations.snps.vcf.gz

#------------- 09 July 2021 
# ok i've just been bumbling the f around, so trying this workflow: https://github.com/enormandeau/stacks_workflow# 

Filtering (STACKS2)
./00-scripts/05_filter_vcf_fast.py 05-stacks/populations.snps.vcf 4 70 0 2 filtered_m4_p70_x0_S2.vcf


# i think my file is corrupted ...
# rerunning more simply (quickly), and this workflow has downstream filtering

populations -P ./denovo_map/stacks/ --popmap ./pop_maps/eximius_popmap_colony_site.txt -t 14 --vcf

# Filtering SNPs in VCF
#
# Usage:
#     <program> input_vcf min_cov percent_genotypes max_pop_fail min_mas output_vcf
#
# Where:
#     input_vcf: is the name of the VCF file to filter
#     min_cov: minimum allele coverage to keep genotype <int>, eg: 4 or more
#     percent_genotypes: minimum percent of genotype data per population <float> eg: 50, 70, 80, 90, 100
#     max_pop_fail: maximum number of populations that can fail percent_genotypes <int> eg: 1, 2, 3
#     min_mas: minimum number of samples with rare allele <int> eg: 2 or more
#     output_vcf: is the name of the filtered VCF
#
# WARNING:
#     The filtering is done purely on a SNP basis. Loci are not taken into account.

# Filtering (STACKS2)
./00-scripts/05_filter_vcf_fast.py 05-stacks/populations.snps.vcf 4 70 0 2 filtered_m4_p70_x0_S2.vcf

### okayyyyy this gives me an empty vcf -.-, too much filtering perhaps
./00-scripts/05_filter_vcf_fast.py 05-stacks/populations.snps.vcf 4 20 0 2 filtered_m4_p20_x0_S2.vcf
# nope

./00-scripts/05_filter_vcf_fast.py 05-stacks/populations.snps.vcf 4 5 50 2 filtered_m4_p5_x50_S2.vcf
# ok this one worked...



# Graphs
./00-scripts/05_filter_vcf.py -i filtered_m4_p70_x0_S2 -o graphs_filtered_m4_p70_x0_S2 -g
# ok that didn't work but I think that's ok. just moving on

# relatedness
vcftools --relatedness --vcf filtered_m4_p5_x50_S2.vcf --out samples.2

# plot
./00-scripts/utility_scripts/plot_relatedness_graphs.R samples.2.relatedness 0.5

# heterozygosity
vcftools --het --vcf filtered_m4_p5_x50_S2.vcf   --out samples

#format data
awk '{print $5,$1,$1}' samples.het | cut -d "_" -f 1,2 > samples.het.data


./00-scripts/utility_scripts/plot_heterozygozity.R samples.het
# this plot did not work


/Applications/plink/plink --make-bed --vcf populations.snps.c_chroms.vcf.gz --out populations.snps.c_chroms --set-missing-var-ids @:# --double-id --allow-extra-chr --noweb

# THIS WORKED!!

/Applications/admixture/admixture populations.snps.c_chroms.bed 3
# lol ok that caused a fatal error


populations -P ./denovo_map/stacks/ --popmap ./pop_maps/eximius_popmap_colony_site.txt -t 14 --vcf -r 70 -p 3 --fstats --min-maf 0.05


########## ok, we are going to start over, starting on N1. the proof of concept seems to work well enough for eximius, but that stuff is known and this one isnt. so!
# denovo alignment, round 2



cat > denovo_N1.sh  
----------------

#!/bin/bash
output=~/denovo_map/stacks-n1
pop_maps=~/pop_maps
samples=~/stacks_demultiplex/samples/eximius/N1

denovo_map.pl -T 14 --popmap $pop_maps/N1_popmap_colony_site.txt -o $output --samples $samples -M 2 -n 3 --paired
        
----------------

# started run Friday at 4:37pm, finished run ~ 6:45pm


populations -P ./denovo_map/stacks-n1/ --popmap ./pop_maps/N1_popmap_colony_site.txt -t 14 --vcf -r 70 -p 3 --fstats --min-maf 0.05


##### 12 July 2021 ######
## and with F2


cat > denovo_F2.sh  
----------------

#!/bin/bash
output=~/denovo_map/stacks-f2
pop_maps=~/pop_maps
samples=~/stacks_demultiplex/samples/eximius/F2

denovo_map.pl -T 14 --popmap $pop_maps/F2_popmap_colony_site.txt -o $output --samples $samples -M 2 -n 3 --paired
        
----------------
# ^ breakdown
## -M : # of mismatches allowed between stacks within individuals (for ustacks)
## -n : number of mismatches allowed between stacks between individuals (for cstacks)

# started Monday 9:45, ended 


populations -P ./denovo_map/stacks-f2/ --popmap ./pop_maps/F2_popmap_colony_site.txt -t 14 --vcf -r 70 -p 3 --fstats --min-maf 0.05

# -r : minimum percentage of individuals in a population required to process a locus for that population.
# -p : minimum number of populations a locus must be present in to process a locus.
# --min-maf : specify a minimum minor allele frequency required to process a nucleotide site at a locus


####### 13 July 2021 #######
# following the tutorial here: http://www.ddocent.com/filtering/

# We are going to only keep variants that have been successfully genotyped in 50% of individuals, a minimum quality score of 30, and a minor allele count of 3.

vcftools --gzvcf eximius.snps.vcf.gz --max-missing 0.5 --mac 3 --minQ 30 --recode --recode-INFO-all --out raw.50mac3

# After filtering, kept 0 out of a possible 29364 Sites
# lol ok then

vcftools --gzvcf eximius.snps.vcf.gz --max-missing 0.2 --mac 3 --minQ 30 --recode --recode-INFO-all --out raw.20mac3
# same

vcftools --gzvcf eximius.snps.vcf.gz --max-missing 0.05 --mac 3 --minQ 30 --recode --recode-INFO-all --out raw.05mac3
#same

vcftools --gzvcf eximius.snps.vcf.gz --mac 3 --minQ 30 --recode --recode-INFO-all --out raw.mac3
#same

vcftools --gzvcf eximius.snps.vcf.gz --max-missing 0.05 --mac 3 --recode --recode-INFO-all --out raw.05mac3
# ok this one actually worked
# After filtering, kept 28049 out of a possible 29364 Sites

vcftools --gzvcf eximius.snps.vcf.gz --max-missing 0.50 --mac 3 --recode --recode-INFO-all --out raw.50mac3
# After filtering, kept 11080 out of a possible 29364 Sites

vcftools --gzvcf eximius.snps.vcf.gz --max-missing 0.30 --mac 3 --recode --recode-INFO-all --out raw.30mac3
# After filtering, kept 17710 out of a possible 29364 Sites


# ok, for the purposes of this exercise, i'm going to use the raw.30mac3.vcf
# filter minimum read depth = 3
vcftools --vcf raw.30mac3.recode.vcf --minDP 3 --recode --recode-INFO-all --out raw.30mac3dp3 
#After filtering, kept 17710 out of a possible 17710 Sites. nice.

# check for potential errors
curl -L -O https://github.com/jpuritz/dDocent/raw/master/scripts/ErrorCount.sh
chmod +x ErrorCount.sh 
./ErrorCount.sh raw.30mac3dp3.recode.vcf 

# get rid of individuals that did not sequence well
vcftools --vcf raw.30mac3dp3.recode.vcf --missing-indv
cat out.imiss
# some individuals have a high amount of missing data


mawk '!/IN/' out.imiss | cut -f5 > totalmissing

gnuplot << \EOF 
set terminal dumb size 120, 30
set autoscale 
unset label
set title "Histogram of % missing data per individual"
set ylabel "Number of Occurrences"
set xlabel "% of missing data"
#set yr [0:100000]
binwidth=0.01
bin(x,width)=width*floor(x/width) + binwidth/2.0
plot 'totalmissing' using (bin($1,binwidth)):(1.0) smooth freq with boxes
pause -1
EOF

# worked! had to install gnuplot on mawk on my comp

# create list of individuals with greater than 50% of missing data
mawk '$5 > 0.5' out.imiss | cut -f1 > lowDP.indv

# remove those individuals
# After filtering, kept 97 out of 138 Individuals

# remove those individuals
vcftools --vcf raw.30mac3dp3.recode.vcf --remove lowDP.indv --recode --recode-INFO-all --out raw.30mac3dplm

# Now that we have removed poor coverage individuals, we can restrict the data to variants called in a high percentage of individuals and filter by mean depth of genotypes

vcftools --vcf raw.30mac3dp3.recode.vcf --max-missing 0.5 --maf 0.05 --recode --recode-INFO-all --out DP3g5maf05 --min-meanDP 5
# After filtering, kept 10892 out of a possible 17710 Sites


# filter by populations specific call rate, starting at site level
first want lists of just individuals from each population

awk '{if($3 == "JatunSacha"){print $1}}' eximius_popmap_colony_site.txt > 1.keep && awk '{if($3 == "Archidona"){print $1}}' eximius_popmap_colony_site.txt > 2.keep && awk '{if($3 == "ViaLoreto"){print $1}}' eximius_popmap_colony_site.txt > 3.keep


# Next, we use VCFtools to estimate missing data for loci in each population
vcftools --vcf DP3g5maf05.recode.vcf --keep 1.keep --missing-site --out 1
vcftools --vcf DP3g5maf05.recode.vcf --keep 2.keep --missing-site --out 2
vcftools --vcf DP3g5maf05.recode.vcf --keep 3.keep --missing-site --out 3


cat 1.lmiss 2.lmiss | awk '{print $1}' | awk '{if($6 > 0.1){print}}'

## ^ trying to do that inc luster, just copied code to my computer, copying badloci back
cat 1.lmiss 2.lmiss 3.lmiss | mawk '!/CHR/' | mawk '$6 > 0.1' | cut -f1,2 >> badloci

# remove those loci
vcftools --vcf DP3g5maf05.recode.vcf --exclude-positions badloci --recode --recode-INFO-all --out DP3g5p5maf05

# ope, no reads left. 
cat 1.lmiss 2.lmiss 3.lmiss | mawk '!/CHR/' | mawk '$6 > 0.65' | cut -f1,2 >> badloci


##### ok, well i think i get the gist of how to use vcf tools to filter, so now i'm going to try and figure out what based on my convo with tom and julia, starting with read depth
# emptying filtering folder to get fresh start

# SITE FILTERING OPTIONS
vcftools --gzvcf eximius.snps.vcf.gz --max-missing 0.50 --mac 3 --recode --recode-INFO-all --out raw.30mac3

# After filtering, kept 11080 out of a possible 29364 Sites


vcftools --vcf raw.30mac3.recode.vcf --minDP 3 --recode --recode-INFO-all --out raw.30mac3dp3 
# After filtering, kept 11080 out of a possible 11080 Sites

vcftools --vcf raw.30mac3dplm.recode.vcf --missing-indv

# for histogram
awk '{print}' out.imiss | cut -f5 > totalmissing


# filter out any that have more than 0.5 missing data
awk '$5 > 0.5' out.imiss | cut -f1 > lowDP.indv

# and remove
vcftools --vcf raw.30mac3dp3.recode.vcf --remove lowDP.indv --recode --recode-INFO-all --out raw.30mac3dplm
# After filtering, kept 99 out of 138 Individuals
# After filtering, kept 11080 out of a possible 11080 Sites


vcftools --vcf raw.30mac3dplm.recode.vcf --depth
vcftools --vcf raw.30mac3dplm.recode.vcf --site-depth
vcftools --vcf raw.30mac3dplm.recode.vcf  --site-mean-depth
vcftools --vcf raw.30mac3dplm.recode.vcf  --geno-depth
vcftools --vcf raw.30mac3dplm.recode.vcf --weir-fst-pop fst.pop


#### rerunning populations, no filtering at that end, and will do filtering with vcf tools (idk, we'll see)
# emptying stacks directory
populations -P ./denovo_map/stacks/ --popmap ./pop_maps/eximius_popmap_colony_site.txt -t 14 --vcf


### FILTERING ##

vcftools --vcf eximius.snps.vcf  --max-missing 0.50 --mac 3 --maf 0.05 --recode --recode-INFO-all --out raw.mm50mac3maf05
# After filtering, kept 19755 out of a possible 174260 Sites

# minDP 
vcftools --vcf raw.mm50mac3maf05.recode.vcf --minDP 3 --recode --recode-INFO-all --out raw.mm50mac3maf05dp3 

#19755 out of a possible 19755 Sites

# minimum mean depth
vcftools --vcf raw.mm50mac3maf05dp3.recode.vcf --min-meanDP 5 --recode --recode-INFO-all --out raw.mm50mac3maf05dp3mdp5
# After filtering, kept 19680 out of a possible 19755 Sites

# remove missing individuals
vcftools --vcf raw.mm50mac3maf05dp3mdp5.recode.vcf --missing-indv

# filter out any that have more than 0.4 missing data
awk '$5 > 0.5' out.imiss | cut -f1 > lowDP.indv

# and remove
vcftools --vcf raw.mm50mac3maf05dp3mdp5.recode.vcf --remove lowDP.indv --recode --recode-INFO-all --out filtered
# 108 out of 138 Individuals
# After filtering, kept 19680 out of a possible 19680 Sites





#### and repeat for N1 #####
vcftools --vcf populations.snps.vcf  --max-missing 0.50 --mac 3 --maf 0.05 --recode --recode-INFO-all --out raw.mm50mac3maf05
# After filtering, kept 3636 out of a possible 80117 Sites, that's too many

vcftools --vcf populations.snps.vcf  --max-missing 0.40 --mac 3 --maf 0.05 --recode --recode-INFO-all --out raw.mm40mac3maf05
# After filtering, kept 8417 out of a possible 80117 Sites, better. we'll see

# minDP 
vcftools --vcf raw.mm40mac3maf05.recode.vcf --minDP 3 --recode --recode-INFO-all --out raw.mm40mac3maf05dp3 
# kept 8417 out of a possible 8417 Sites

# min-mean DP
vcftools --vcf raw.mm40mac3maf05dp3.recode.vcf --min-meanDP 5 --recode --recode-INFO-all --out raw.mm40mac3maf05dp3mdp5
# kept 7400 out of a possible 8417 Sites


# remove missing individuals
vcftools --vcf raw.mm40mac3maf05dp3mdp5.recode.vcf --missing-indv
# oh yikes, some individuals have a LOT of missing data 

# filter out any that have more than 0.7 missing data
awk '$5 > 0.7' out.imiss | cut -f1 > lowDP.indv


# and remove
vcftools --vcf raw.mm40mac3maf05dp3mdp5.recode.vcf --remove lowDP.indv --recode --recode-INFO-all --out filtered

# After filtering, kept 19 out of 32 Individuals
# After filtering, kept 7400 out of a possible 7400 Sites


#### going for F2 ####
# first, make vcf file
populations -P ./denovo_map/stacks-f2/ --popmap ./pop_maps/F2_popmap_colony_site.txt -t 14 --vcf


vcftools --vcf populations.snps.vcf  --max-missing 0.40 --mac 3 --maf 0.05 --recode --recode-INFO-all --out raw.mm40mac3maf05
# After filtering, kept 17574 out of a possible 175555 Sites


# minDP 
vcftools --vcf raw.mm40mac3maf05.recode.vcf --minDP 3 --recode --recode-INFO-all --out raw.mm40mac3maf05dp3 
# After filtering, kept 17574 out of a possible 17574 Sites


# min-mean DP
vcftools --vcf raw.mm40mac3maf05dp3.recode.vcf --min-meanDP 5 --recode --recode-INFO-all --out raw.mm40mac3maf05dp3mdp5
#After filtering, kept 17217 out of a possible 17574 Sites


# remove missing individuals
vcftools --vcf raw.mm40mac3maf05dp3mdp5.recode.vcf --missing-indv
# woah, they're either above 0.75 or below 0.25


# filter out any that have more than 0.5 missing data
awk '$5 > 0.5' out.imiss | cut -f1 > lowDP.indv


# and remove
vcftools --vcf raw.mm40mac3maf05dp3mdp5.recode.vcf --remove lowDP.indv --recode --recode-INFO-all --out filtered
# After filtering, kept 12 out of 29 Individuals, lol
# After filtering, kept 17217 out of a possible 17217 Sites


### redid F2 --> check log ##



####### August 18, 2022 ###########

# trying to run the filtering as one single step, use for loop for all filtering params


vcftools --vcf eximius.snps.vcf --max-missing 0.50 \
--mac 3 --minDP 3 --min-meanDP 5 \
--recode --recode-INFO-all \
--out raw.mm50mac3dp3mdp5

vcftools --vcf raw.mm50mac3dp3mdp5.recode.vcf --missing-indv

awk '$5 > 0.5' out.imiss | cut -f1 > lowDP.indv

vcftools --vcf raw.mm50mac3dp3mdp5.recode.vcf \
--remove lowDP.indv --recode --recode-INFO-all \
--out exi.1

# for loop to do it automatically for all parameters


#maxmiss = 40 50 60
#minDP = 3 5

# First looping var with list of *.snp file

for vcf in 60 70 80
do
  for maxmiss in .40 .50 .60
	do
	for minDP in 3 5
	do
		echo $vcf $maxmiss $minDP
 

	vcftools --vcf populations.${vcf}.snps.vcf --max-missing $maxmiss \
	--mac 3 --minDP $minDP --min-meanDP 5 \
	--recode --recode-INFO-all \
	--out raw.temp

	vcftools --vcf raw.temp.recode.vcf --missing-indv

	awk '$5 > 0.5' out.imiss | cut -f1 > lowDP.indv

	vcftools --vcf raw.temp.recode.vcf \
	--remove lowDP.indv --recode --recode-INFO-all \
	--out minDP${minDP}.maxmiss${maxmiss}.${vcf}.snps

rm raw.temp.recode.vcf
rm out.imiss
rm lowDP.indv

done
done
done


 		
## need bed file for admixture, plink doesn't like chromosome numbers exceeding 23, need to rename scaffolds

sed '16,$s/^/scaffold_/' minDP3.maxmiss.50.70.snps.recode.vcf > exi.scaffolds.vcf

## make bed file
./plink2 --vcf exi.scaffolds.vcf --allow-extra-chr 0 --double-id --make-bed --out exi.scaffolds

cp exi.scaffolds.* ../../admixture/exi

nano exi_runadmixture.sh

for K in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20; \
do ./admixture \
--cv=10 \
exi.scaffolds.bed \
$K | tee log${K}.out; \
done

./exi_runadmixture.sh

grep -h CV log*out > CV.csv


## do the same for f1


sed '16,$s/^/scaffold_/' minDP3.maxmiss.40.70.snps.recode.vcf > f1.scaffolds.vcf

## make bed file
./plink2 --vcf f1.scaffolds.vcf --allow-extra-chr 0 --double-id --make-bed --out f1.scaffolds

cp f1.scaffolds.* ../../admixture/n1

nano f1_runadmixture.sh

for K in 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20; \
do ./admixture \
--cv=10 \
f1.scaffolds.bed \
$K | tee log${K}.out; \
done

./f1_runadmixture.sh

grep -h CV log*out > CV.csv



## do the same for f2

# same filtering parameters for this species
sed '16,$s/^/scaffold_/' minDP3.maxmiss.40.70.snps.recode.vcf > f2.scaffolds.vcf

## make bed file
./plink2 --vcf f2.scaffolds.vcf --allow-extra-chr 0 --double-id --make-bed --out f2.scaffolds

cp f2.scaffolds.* ../../admixture/f2

nano f2_runadmixture.sh

for K in 1 2 3 4 5 6 7 8 9 10 11 12; \
do ./admixture \
--cv=10 \
f2.scaffolds.bed \
$K | tee log${K}.out; \
done

./f2_runadmixture.sh

grep -h CV log*out > CV.csv


### for exi at jatun sacha only
nano exi_subset.txt

Ex11.3
Ex11.4
Ex11.5
Ex12.1
Ex12.7
Ex14.2
Ex14.4
Ex02.3
Ex05.5
Ex06A.5
Ex06B.1
Ex06B.6
Ex02.6
Ex02.8
Ex05.3
Ex05.6
Ex06A.6
Ex06B.3
Ex06B.5
Ex06B.8
Ex12.5
Ex05.1
Ex06A.3
Ex07.1
Ex07.3
Ex08.1
Ex08.3
Ex06A.1
Ex06B.4
Ex06B.7
Ex07.5
Ex08.7
Ex08.8
Ex12.3
Ex12.6
Ex06B.2
Ex07.2
Ex08.6
Ex02.2
Ex02.4
Ex07.4
Ex07.6
Ex07.8
Ex08.2
Ex10.2
Ex10.5
Ex11.1
Ex14.5
Ex02.14
Ex02.1
Ex12.14


vcftools --vcf exi/exi.scaffolds.vcf --keep exi_subset.txt --out exi_subset --recode


.././plink2 --vcf exi_subset.js.vcf --allow-extra-chr 0 --double-id --make-bed --out exi_subset.js

nano exi_js_runadmixture.sh

for K in 1 2 3 4 5 6 7 8 9 10 11 12; \
do ./admixture \
--cv=10 \
exi_subset.js.bed \
$K | tee log${K}.out; \
done


chmod 775 exi_js_runadmixture.sh
./exi_js_runadmixture.sh

grep -h CV log*out > CV.csv

### for archidona
nano exi_archi_subset.txt

Exi_Archi_11.8.1.01
Exi_Archi_11.8.1.02
Exi_Archi_11.8.1.04
Exi_Archi_11.8.1.05
Exi_Archi_11.8.5.01
Exi_Archi_11.8.5.02
Exi_Archi_11.8.5.03
Exi_Archi_11.8.5.04
Exi_Archi_11.8.1.06
Exi_Archi_11.8.1.07
Exi_Archi_11.8.1.08
Exi_Archi_11.8.1.09
Exi_Archi_11.8.1.10
Exi_Archi_11.8.2.01
Exi_Archi_11.8.2.02
Exi_Archi_11.8.2.03
Exi_Archi_11.8.4.05
Exi_Archi_11.8.5.05


vcftools --vcf ../exi/exi.scaffolds.vcf --keep exi_archi_subset.txt --out exi_archi_subset --recode


.././plink2 --vcf exi_archi_subset.recode.vcf --allow-extra-chr 0 --double-id --make-bed --out exi_archi_subset


nano exi_archi_runadmixture.sh

for K in 1 2 3 4 5 6 7 8 9 10 11 12; \
do ./admixture \
--cv=10 \
exi_archi_subset.bed \
$K | tee log${K}.out; \
done

chmod 775 exi_archi_runadmixture.sh

./exi_archi_runadmixture.sh


## hmm, got Error: detected that all genotypes are missing for a SNP locus.
.././plink2 --bfile exi_archi_subset --geno 0.999 --make-bed --out exi_archi_subset2

nano exi_archi_runadmixture.sh

for K in 1 2 3 4 5 6 7 8 9 10 11 12; \
do ./admixture \
--cv=10 \
exi_archi_subset2.bed \
$K | tee log${K}.out; \
done

chmod 775 exi_archi_runadmixture.sh

./exi_archi_runadmixture.sh

grep -h CV log*out > CV.csv


### for VL
nano exi_vl_subset.txt

Exi_VL_41.2.01  
Exi_VL_41.2.02  
Exi_VL_41.2.03  
Exi_VL_41.2.04  
Exi_VL_17.5.01  
Exi_VL_17.5.03  
Exi_VL_17.5.05  
Exi_VL_17.5.06  
Exi_VL_Bridge.1.01  
Exi_VL_Bridge.1.03  
Exi_VL_Bridge.1.04  
Exi_VL_24.1.01  
Exi_VL_24.1.02  
Exi_VL_24.1.03  
Exi_VL_24.1.04  
Exi_VL_24.1.05  
Exi_VL_24.1.06  
Exi_VL_9.5.1.01 
Exi_VL_9.5.1.02 
Exi_VL_9.5.1.03 
Exi_VL_Bridge.1.06  
Exi_VL_Bridge.1.07  
Exi_VL_10.5.08  
Exi_VL_9.5.1.05 
Exi_VL_Bridge.1.05  
Exi_VL_10.5.04  
Exi_VL_10.5.05  
Exi_VL_10.5.06  
Exi_VL_10.5.07 


vcftools --vcf ../exi/exi.scaffolds.vcf --keep exi_vl_subset.txt --out exi_vl_subset --recode


.././plink2 --vcf exi_vl_subset.recode.vcf --allow-extra-chr 0 --double-id --make-bed --out exi_vl_subset


nano exi_vl_runadmixture.sh

## same, Error: detected that all genotypes are missing for a SNP locus.
.././plink2 --bfile exi_vl_subset --geno 0.999 --make-bed --out exi_vl_subset2

for K in 1 2 3 4 5 6 7 8 9 10 11 12; \
do .././admixture \
--cv=10 \
exi_vl_subset.bed \
$K | tee log${K}.out; \
done

chmod 775 exi_vl_runadmixture.sh

./exi_vl_runadmixture.sh
grep -h CV log*out > CV.csv


## F1 - jatun sacha only
nano f1_js_subset.txt

Ex12.N1.1
Ex12.N1.3
Ex12.N1.2
Ex06B.N1.1
Ex06B.N1.2
Ex17.N1.1
Ex08.N1.2
Ex08.N1.3
Ex08.N1.5


vcftools --vcf ../f1/f1.scaffolds.vcf --keep f1_js_subset.txt --out f1_js_subset --recode


.././plink2 --vcf f1_js_subset.recode.vcf --allow-extra-chr 0 --double-id --geno 0.999 --make-bed --out f1_js_subset


nano f1_js_runadmixture.sh

for K in 1 2 3 4 5 6 7 8 9 10 11 12; \
do .././admixture \
--cv=10 \
f1_js_subset.bed \
$K | tee log${K}.out; \
done

chmod 775 f1_js_runadmixture.sh

./f1_js_runadmixture.sh

grep -h CV log*out > CV.csv


##### Final list of eximius individuals
nano exi_list.txt

Ex11.3.*
Ex11.4.*
Ex11.5.*
Ex12.1.*
Ex12.7.*
Ex14.2.*
Ex14.4.*
Ex02.3.*
Ex05.5.*
Ex06A.5.*
Ex06B.1.*
Ex06B.6.*
Ex02.6.*
Ex02.8.*
Ex05.3.*
Ex05.6.*
Ex06A.6.*
Ex06B.3.*
Ex06B.5.*
Ex06B.8.*
Ex12.5.*
Ex05.1.*
Ex06A.3.*
Ex07.1.*
Ex07.3.*
Ex08.1.*
Ex08.3.*
Ex06A.1.*
Ex06B.4.*
Ex06B.7.*
Ex07.5.*
Ex08.7.*
Ex08.8.*
Ex12.3.*
Ex12.6.*
Ex06B.2.*
Ex07.2.*
Ex08.6.*
Ex02.2.*
Ex02.4.*
Ex07.4.*
Ex07.6.*
Ex07.8.*
Ex08.2.*
Ex10.2.*
Ex10.5.*
Ex11.1.*
Ex14.5.*
Ex02.14.*
Ex02.1.*
Ex12.14.*
Exi_VL_41.2.01.*
Exi_VL_41.2.02.*
Exi_VL_41.2.03.*
Exi_VL_41.2.04.*
Exi_VL_17.5.01.*
Exi_VL_17.5.03.*
Exi_VL_17.5.05.*
Exi_VL_17.5.06.*
Exi_VL_Bridge.1.01.*
Exi_VL_Bridge.1.03.*
Exi_VL_Bridge.1.04.*
Exi_VL_24.1.01.*
Exi_VL_24.1.02.*
Exi_VL_24.1.03.*
Exi_VL_24.1.04.*
Exi_VL_24.1.05.*
Exi_VL_24.1.06.*
Exi_VL_9.5.1.01.*
Exi_VL_9.5.1.02.*
Exi_VL_9.5.1.03.*
Exi_VL_Bridge.1.06.*
Exi_VL_Bridge.1.07.*
Exi_VL_10.5.08.*
Exi_VL_9.5.1.05.*
Exi_VL_Bridge.1.05.*
Exi_VL_10.5.04.*
Exi_VL_10.5.05.*
Exi_VL_10.5.06.*
Exi_VL_10.5.07.*
Exi_VL_9.5.01.*
Exi_Archi_11.8.1.01.*
Exi_Archi_11.8.1.02.*
Exi_Archi_11.8.1.04.*
Exi_Archi_11.8.1.05.*
Exi_Archi_11.8.5.01.*
Exi_Archi_11.8.5.02.*
Exi_Archi_11.8.5.03.*
Exi_Archi_11.8.5.04.*
Exi_Archi_11.8.1.06.*
Exi_Archi_11.8.1.07.*
Exi_Archi_11.8.1.08.*
Exi_Archi_11.8.1.09.*
Exi_Archi_11.8.1.10.*
Exi_Archi_11.8.2.01.*
Exi_Archi_11.8.2.02.*
Exi_Archi_11.8.2.03.*
Exi_Archi_11.8.4.05.*
Exi_Archi_11.8.5.05.*




# want to get the raw, de-multiplexed files and upload to ncbi SRA

## loop to move only individuals that made it past filtering into a new folder

#!/bin/sh

source_path=`cat exi_filterd/exi_list.txt`
for i in $source_path
do
  cp exi/$i exi_filtered/
done

# copy to my computer
scp -r straus@zoology.ubc.ca:/Shared/homes/s/straus/GBS/stacks_demultiplex/samples/eximius/exi_filtered .

# repeat with 2 kleptoparasite species

nano n1_list.txt

Ex12.N1.1.*
Ex12.N1.3.*
Ex12.N1.2.*
Ex06B.N1.1.*
Ex06B.N1.2.*
Ex17.N1.1.*
Ex08.N1.2.*
Ex08.N1.3.*
Ex08.N1.5.*
Exi_VL_9.5.2.N1.01.*
Exi_VL_9.5.2.N1.02.*
Exi_VL_9.5.2.N1.03.*
Exi_VL_9.5.2.N1.04.*
Exi_Archi_11.8.3.N1.01.*
Exi_Archi_11.8.3.N1.03.*
Exi_Archi_11.8.3.N1.04.*
Exi_Archi_11.8.5.N1.02.*
Exi_Archi_11.8.1.N1.01.*
Exi_VL_24.1.N1.01.*


nano f1_filtered

#!/bin/sh

source_path=`cat n1_list.txt`
for i in $source_path
do
  cp F1/$i f1_filtered/
done



nano f2_list.txt

Ex07.F2.1.*
Ex07.F2.2.*
Ex07.F2.3.*
Ex07.F2.4.*
Ex02.F2.8.*
Ex02.F2.1.*
Ex02.F2.2.*
Ex14A.F2.1.*
Ex02.F2.7.*
Ex08.F2.2.*
Ex14A.F2.2.*


nano copy_f2

#!/bin/sh

source_path=`cat f2_list.txt`
for i in $source_path
do
  cp F2/$i f2_filtered/
done

## total number of files = (99 + 19 + 11) * 2 = 129 * 2 = 258
